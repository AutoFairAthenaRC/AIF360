{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness auditing for subgroups using Fairness Aware Counterfactuals for Subgroups (FACTS).\n",
    "\n",
    "[FACTS](https://arxiv.org/abs/2306.14978) is an efficient, model-agnostic, highly parameterizable, and explainable framework for evaluating subgroup fairness through counterfactual explanations.\n",
    "\n",
    "In this notebook, we will see how to use this algorithm for discovering subgroups where the bias of a model (logistic regression for simplicity) between Males and Females is high.\n",
    "\n",
    "We will use the Adult dataset from UCI ([reference](https://archive.ics.uci.edu/ml/datasets/adult))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies\n",
    "\n",
    "As usual in python, the first step is to import all necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from aif360.sklearn.datasets.openml_datasets import fetch_adult\n",
    "from aif360.sklearn.detectors.facts.clean import clean_dataset\n",
    "from aif360.sklearn.detectors.facts import FACTS, print_recourse_report\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can change the `random_seed` variable to `None` if you would like for the pseudo-random parts to actually change between runs. We have set it to a specific value for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 131313 # for reproducibility"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(16.999, 26.0]</td>\n",
       "      <td>Private</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FullTime</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(34.0, 41.0]</td>\n",
       "      <td>Private</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Married</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>OverTime</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(26.0, 34.0]</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Married</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FullTime</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(41.0, 50.0]</td>\n",
       "      <td>Private</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Married</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FullTime</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(26.0, 34.0]</td>\n",
       "      <td>Private</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MidTime</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  workclass  education-num      marital-status  \\\n",
       "0  (16.999, 26.0]    Private            7.0       Never-married   \n",
       "1    (34.0, 41.0]    Private            9.0  Married-civ-spouse   \n",
       "2    (26.0, 34.0]  Local-gov           12.0  Married-civ-spouse   \n",
       "3    (41.0, 50.0]    Private           10.0  Married-civ-spouse   \n",
       "4    (26.0, 34.0]    Private            6.0       Never-married   \n",
       "\n",
       "          occupation   relationship   race   sex  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct      Own-child  Black  Male           0.0           0.0   \n",
       "1    Farming-fishing        Married  White  Male           0.0           0.0   \n",
       "2    Protective-serv        Married  White  Male           0.0           0.0   \n",
       "3  Machine-op-inspct        Married  Black  Male        7688.0           0.0   \n",
       "4      Other-service  Not-in-family  White  Male           0.0           0.0   \n",
       "\n",
       "  hours-per-week native-country  income  \n",
       "0       FullTime  United-States       0  \n",
       "1       OverTime  United-States       0  \n",
       "2       FullTime  United-States       1  \n",
       "3       FullTime  United-States       1  \n",
       "4        MidTime  United-States       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y, sample_weight = fetch_adult()\n",
    "data = clean_dataset(X.assign(income=y), \"adult\")\n",
    "display(data.head())\n",
    "\n",
    "y = data['income']\n",
    "X = data.drop('income', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=random_seed, stratify=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and test\n",
    "\n",
    "We use the train set to train a simple logistic regression model. This will serve as the demonstrative model, which we will then treat as a black box and apply our algorithm.\n",
    "\n",
    "Of course, any model can be used in its place. Our purpose here is not to produce a very good model, but to audit the fairness of an existing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = X._get_numeric_data().columns.to_list()\n",
    "cate_features = X.select_dtypes(include=['object','category']).columns.to_list()\n",
    "\n",
    "cat_transf = ColumnTransformer(transformers=[\n",
    "    (\"ohe\", OneHotEncoder(), cate_features)\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"ohe\", cat_transf),\n",
    "    (\"clf\", LogisticRegression(max_iter=1500))\n",
    "])\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 85.16%\n"
     ]
    }
   ],
   "source": [
    "preds_Xtest = model.predict(X_test)\n",
    "print(f\"Accuracy = {(y_test.values == preds_Xtest).sum() / y_test.shape[0]:.2%}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution\n",
    "\n",
    "Here begins the actual contribution of our work. Specifically, we demonstrate the generation of candidate subgroups and counterfactuals and the detection of those subgroups showcase the highest unfairness, with respect to one of several metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Subgroups Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = FACTS(\n",
    "    estimator=model,\n",
    "    prot_attr=\"sex\",\n",
    "    feature_weights={f: 1 for f in X.columns}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing candidate subgroups.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 1046/1046 [00:00<00:00, 922270.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subgroups: 563\n",
      "Computing candidate recourses for all subgroups.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 563/563 [00:00<00:00, 101591.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing percentages of individuals flipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 590/590 [00:13<00:00, 42.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 416/416 [00:12<00:00, 33.39it/s]\n"
     ]
    }
   ],
   "source": [
    "detector = detector.fit(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfair Groups Detection (using \"Equal Choice for Recourse\" metric)\n",
    "\n",
    "Here we showcase the `bias_scan` method of our detector, which ranks subpopulation groups from most to least unfair, with respect to the chosen metric and, of course, the protected attribute.\n",
    "\n",
    "For the purposes of this demo, we use the \"Equal Choice for Recourse\" metric. This metric claims that the classifier acts fairly for the group in question if the protected subgroups can choose among the same number of sufficiently effective actions to achieve recourse. By sufficiently effective we mean those actions (out of all candidates) which work for at least $100\\phi \\%$ (for $\\phi \\in [0,1]$) of the subgroup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_groups, subgroup_costs = detector.bias_scan(\n",
    "    metric=\"equal-choice-for-recourse\",\n",
    "    phi=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If \u001b[1mage = (26.0, 34.0], hours-per-week = FullTime\u001b[0m:\n",
      "\tProtected Subgroup '\u001b[1mFemale\u001b[0m', \u001b[34m10.59%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mage = (41.0, 50.0]\u001b[39m, \u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m7.73%\u001b[39m and counterfactual cost = 2.0.\n",
      "\t\tMake \u001b[1m\u001b[31mage = (41.0, 50.0]\u001b[39m\u001b[0m with effectiveness \u001b[32m3.98%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mage = (34.0, 41.0]\u001b[39m, \u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m5.39%\u001b[39m and counterfactual cost = 2.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m0.00\u001b[39m\n",
      "\tProtected Subgroup '\u001b[1mMale\u001b[0m', \u001b[34m13.78%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mage = (41.0, 50.0]\u001b[39m, \u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m19.66%\u001b[39m and counterfactual cost = 2.0.\n",
      "\t\tMake \u001b[1m\u001b[31mage = (41.0, 50.0]\u001b[39m\u001b[0m with effectiveness \u001b[32m10.63%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mage = (34.0, 41.0]\u001b[39m, \u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m13.39%\u001b[39m and counterfactual cost = 2.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m-3.00\u001b[39m\n",
      "\t\u001b[35mBias against Female due to Equal Effectiveness. Unfairness score = 3.\u001b[39m\n",
      "If \u001b[1mage = (26.0, 34.0], capital-loss = 0.0, hours-per-week = FullTime\u001b[0m:\n",
      "\tProtected Subgroup '\u001b[1mFemale\u001b[0m', \u001b[34m10.34%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mage = (41.0, 50.0]\u001b[39m, \u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m7.67%\u001b[39m and counterfactual cost = 2.0.\n",
      "\t\tMake \u001b[1m\u001b[31mage = (41.0, 50.0]\u001b[39m\u001b[0m with effectiveness \u001b[32m4.08%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mage = (34.0, 41.0]\u001b[39m, \u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m5.28%\u001b[39m and counterfactual cost = 2.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m0.00\u001b[39m\n",
      "\tProtected Subgroup '\u001b[1mMale\u001b[0m', \u001b[34m13.27%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mage = (41.0, 50.0]\u001b[39m, \u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m18.43%\u001b[39m and counterfactual cost = 2.0.\n",
      "\t\tMake \u001b[1m\u001b[31mage = (41.0, 50.0]\u001b[39m\u001b[0m with effectiveness \u001b[32m9.27%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mage = (34.0, 41.0]\u001b[39m, \u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m11.92%\u001b[39m and counterfactual cost = 2.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m-2.00\u001b[39m\n",
      "\t\u001b[35mBias against Female due to Equal Effectiveness. Unfairness score = 2.\u001b[39m\n",
      "If \u001b[1mhours-per-week = FullTime, native-country = United-States\u001b[0m:\n",
      "\tProtected Subgroup '\u001b[1mFemale\u001b[0m', \u001b[34m41.66%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m2.62%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = BrainDrain\u001b[39m\u001b[0m with effectiveness \u001b[32m1.79%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m0.00\u001b[39m\n",
      "\tProtected Subgroup '\u001b[1mMale\u001b[0m', \u001b[34m46.78%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m10.08%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = BrainDrain\u001b[39m\u001b[0m with effectiveness \u001b[32m8.70%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m-1.00\u001b[39m\n",
      "\t\u001b[35mBias against Female due to Equal Effectiveness. Unfairness score = 1.\u001b[39m\n",
      "If \u001b[1mhours-per-week = FullTime, race = White\u001b[0m:\n",
      "\tProtected Subgroup '\u001b[1mFemale\u001b[0m', \u001b[34m36.15%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m2.88%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = BrainDrain\u001b[39m\u001b[0m with effectiveness \u001b[32m1.92%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m0.00\u001b[39m\n",
      "\tProtected Subgroup '\u001b[1mMale\u001b[0m', \u001b[34m44.58%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m10.18%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = BrainDrain\u001b[39m\u001b[0m with effectiveness \u001b[32m8.74%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m-1.00\u001b[39m\n",
      "\t\u001b[35mBias against Female due to Equal Effectiveness. Unfairness score = 1.\u001b[39m\n",
      "If \u001b[1mhours-per-week = FullTime, native-country = United-States, race = White\u001b[0m:\n",
      "\tProtected Subgroup '\u001b[1mFemale\u001b[0m', \u001b[34m33.03%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m3.08%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = BrainDrain\u001b[39m\u001b[0m with effectiveness \u001b[32m2.03%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m0.00\u001b[39m\n",
      "\tProtected Subgroup '\u001b[1mMale\u001b[0m', \u001b[34m40.67%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m10.69%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = BrainDrain\u001b[39m\u001b[0m with effectiveness \u001b[32m9.14%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m-1.00\u001b[39m\n",
      "\t\u001b[35mBias against Female due to Equal Effectiveness. Unfairness score = 1.\u001b[39m\n",
      "If \u001b[1mcapital-loss = 0.0, hours-per-week = FullTime, native-country = United-States, race = White\u001b[0m:\n",
      "\tProtected Subgroup '\u001b[1mFemale\u001b[0m', \u001b[34m32.13%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m2.85%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = BrainDrain\u001b[39m\u001b[0m with effectiveness \u001b[32m1.85%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m0.00\u001b[39m\n",
      "\tProtected Subgroup '\u001b[1mMale\u001b[0m', \u001b[34m39.52%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m10.04%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = BrainDrain\u001b[39m\u001b[0m with effectiveness \u001b[32m8.48%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m-1.00\u001b[39m\n",
      "\t\u001b[35mBias against Female due to Equal Effectiveness. Unfairness score = 1.\u001b[39m\n",
      "If \u001b[1mcapital-gain = 0.0, hours-per-week = FullTime, native-country = United-States, race = White\u001b[0m:\n",
      "\tProtected Subgroup '\u001b[1mFemale\u001b[0m', \u001b[34m31.91%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m2.64%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = BrainDrain\u001b[39m\u001b[0m with effectiveness \u001b[32m1.79%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m0.00\u001b[39m\n",
      "\tProtected Subgroup '\u001b[1mMale\u001b[0m', \u001b[34m39.44%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = OverTime\u001b[39m\u001b[0m with effectiveness \u001b[32m10.32%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mhours-per-week = BrainDrain\u001b[39m\u001b[0m with effectiveness \u001b[32m8.76%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m-1.00\u001b[39m\n",
      "\t\u001b[35mBias against Female due to Equal Effectiveness. Unfairness score = 1.\u001b[39m\n",
      "If \u001b[1mmarital-status = Divorced\u001b[0m:\n",
      "\tProtected Subgroup '\u001b[1mFemale\u001b[0m', \u001b[34m27.00%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mmarital-status = Married-civ-spouse\u001b[39m\u001b[0m with effectiveness \u001b[32m7.25%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m0.00\u001b[39m\n",
      "\tProtected Subgroup '\u001b[1mMale\u001b[0m', \u001b[34m10.45%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mmarital-status = Married-civ-spouse\u001b[39m\u001b[0m with effectiveness \u001b[32m11.20%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m-1.00\u001b[39m\n",
      "\t\u001b[35mBias against Female due to Equal Effectiveness. Unfairness score = 1.\u001b[39m\n",
      "If \u001b[1mage = (26.0, 34.0]\u001b[0m:\n",
      "\tProtected Subgroup '\u001b[1mFemale\u001b[0m', \u001b[34m20.08%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mage = (41.0, 50.0]\u001b[39m\u001b[0m with effectiveness \u001b[32m4.07%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mage = (34.0, 41.0]\u001b[39m\u001b[0m with effectiveness \u001b[32m2.22%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m0.00\u001b[39m\n",
      "\tProtected Subgroup '\u001b[1mMale\u001b[0m', \u001b[34m25.40%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mage = (41.0, 50.0]\u001b[39m\u001b[0m with effectiveness \u001b[32m11.93%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mage = (34.0, 41.0]\u001b[39m\u001b[0m with effectiveness \u001b[32m6.92%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m-1.00\u001b[39m\n",
      "\t\u001b[35mBias against Female due to Equal Effectiveness. Unfairness score = 1.\u001b[39m\n",
      "If \u001b[1mage = (26.0, 34.0], capital-loss = 0.0\u001b[0m:\n",
      "\tProtected Subgroup '\u001b[1mFemale\u001b[0m', \u001b[34m19.56%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mage = (41.0, 50.0]\u001b[39m\u001b[0m with effectiveness \u001b[32m3.93%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mage = (34.0, 41.0]\u001b[39m\u001b[0m with effectiveness \u001b[32m2.15%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m0.00\u001b[39m\n",
      "\tProtected Subgroup '\u001b[1mMale\u001b[0m', \u001b[34m24.48%\u001b[39m covered\n",
      "\t\tMake \u001b[1m\u001b[31mage = (41.0, 50.0]\u001b[39m\u001b[0m with effectiveness \u001b[32m11.00%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\tMake \u001b[1m\u001b[31mage = (34.0, 41.0]\u001b[39m\u001b[0m with effectiveness \u001b[32m6.16%\u001b[39m and counterfactual cost = 1.0.\n",
      "\t\t\u001b[1mAggregate cost\u001b[0m of the above recourses = \u001b[35m-1.00\u001b[39m\n",
      "\t\u001b[35mBias against Female due to Equal Effectiveness. Unfairness score = 1.\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "print_recourse_report(\n",
    "    top_groups,\n",
    "    subgroup_costs=subgroup_costs,\n",
    "    show_then_costs=True,\n",
    "    show_subgroup_costs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short Description of all Definitions / Metrics of Subgroup Recourse Fairness\n",
    "\n",
    "Here we give a brief description of each of the metrics available in our framework apart from \"Equal Choice for Recourse\".\n",
    "\n",
    "## Equal Effectiveness\n",
    "\n",
    "The classifier is considered to act fairly for a population group if the same proportion of individuals in the protected subgroups can achieve recourse.\n",
    "\n",
    "## Equal Effectiveness within Budget\n",
    "\n",
    "The classifier is considered to act fairly for a population group if the same proportion of individuals in the protected subgroups can achieve recourse with a cost at most $c$, where $c$ is some user-provided cost budget.\n",
    "\n",
    "## Equal Cost of Effectiveness\n",
    "\n",
    "The classifier is considered to act fairly for a population group if the minimum cost required to be sufficiently effective in the protected subgroups is equal. Again, as in \"Equal Choice for Recourse\", by \"sufficiently effective\" we refer to those actions that successfully flip the model's decision for at least $100\\phi \\%$ (for $\\phi \\in [0,1]$) of the subgroup.\n",
    "\n",
    "## Equal (Conditional) Mean Recourse\n",
    "\n",
    "This definition extends the notion of *burden* from literature ([reference](https://dl.acm.org/doi/10.1145/3375627.3375812)) to the case where not all individuals may achieve recourse. Omitting some details, given any set of individuals, the **conditional mean recourse cost** is the mean recourse cost among the subset of individuals that can actually achieve recourse, i.e. by at least one of the available actions.\n",
    "\n",
    "Given the above, this definition considers the classifier to act fairly for a population group if the (conditional) mean recourse cost for the protected subgroups is the same.\n",
    "\n",
    "## Fair Effectiveness-Cost Trade-Off\n",
    "\n",
    "This is the strictest definition, which considers the classifier to act fairly for a population group only if the protected subgroups have the same effectiveness-cost distribution (checked in the implementation via a statistical test).\n",
    "\n",
    "Equivalently, Equal Effectiveness within Budget must hold for *every* value of the cost budget $c$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
